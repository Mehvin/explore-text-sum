{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This program changes CNN & Dailymail datasets to the correct format for extractive method\n",
    "# Correct format (.json)\n",
    "# E.g {\"id\":\"777\", \"text\":\"Scientists have just ...\"}\n",
    "# Version 2 - gets the 30% testing datasets\n",
    "\n",
    "import os\n",
    "\n",
    "pre_extractive_dataset = \"/home/kawaijoe/Dataset/cnn-dailymail-master/pre_extractive_dataset\"\n",
    "\n",
    "extractive_dataset = \"/home/kawaijoe/Dataset/cnn-dailymail-master/extractive_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function removes the Index Error\n",
    "def remove_dash_error(data):\n",
    "    data = data.replace(\" - \", \" \")\n",
    "    data = data.replace(\" -\", \" \")\n",
    "    data = data.replace(\"- \", \" \")\n",
    "    data = data.replace(\" -- \", \" \")\n",
    "    data = data.replace(\" --\", \" \")\n",
    "    data = data.replace(\"-- \", \" \")\n",
    "\n",
    "    \n",
    "    data = data.replace(\" — \", \" \")\n",
    "    data = data.replace(\" —\", \" \")\n",
    "    data = data.replace(\"— \", \" \")\n",
    "    data = data.replace(\" —— \", \" \")\n",
    "    data = data.replace(\" ——\", \" \")\n",
    "    data = data.replace(\"—— \", \" \")\n",
    "    \n",
    "    data = data.replace(\" – \", \" \")\n",
    "    data = data.replace(\"– \", \" \")\n",
    "    data = data.replace(\" –\", \" \")\n",
    "    data = data.replace(\" –– \", \" \")\n",
    "    data = data.replace(\"–– \", \" \")\n",
    "    data = data.replace(\" ––\", \" \")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extractive datasets done!\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(extractive_dataset)\n",
    "\n",
    "file_count = 1\n",
    "\n",
    "for file in sorted(os.listdir(pre_extractive_dataset)):\n",
    "    new_filename = str(file_count) + \".json\"\n",
    "    new_filepath = os.path.join(extractive_dataset, new_filename)\n",
    "    with open(pre_extractive_dataset + '/' + file, 'r') as f:\n",
    "        pre_data = \" \".join(line.strip() for line in f)\n",
    "    \n",
    "    # Removing @highlight/summary parts\n",
    "    index = pre_data.find('@highlight')\n",
    "    pre_data = pre_data[:index]\n",
    "        \n",
    "    pre_data = pre_data.replace(\"\\\\\", \"/\") # For 4425.json - JSONDecodeError: Invalid \\escape problem\n",
    "    pre_data = pre_data.replace(\"'\", \"\\'\")\n",
    "    pre_data = pre_data.replace('\"', \"\\'\")\n",
    "    pre_data = remove_dash_error(pre_data)\n",
    "\n",
    "    data = \"{\\\"id\\\":\\\"\" + str(file_count) + \"\\\", \\\"text\\\":\\\"\" + pre_data + \"\\\"}\"\n",
    "    \n",
    "    with open(new_filepath, \"a\") as f:\n",
    "        f.write(data)\n",
    "    file_count = file_count + 1\n",
    "    \n",
    "print(\"Extractive datasets done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
