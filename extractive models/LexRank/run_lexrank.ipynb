{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LexRank: Graph-based Centrality as Salience in Text Summarization\n",
    "\n",
    "Official Paper: http://tangra.si.umich.edu/~radev/lexrank/lexrank.pdf\n",
    "\n",
    "GitHub: https://github.com/miso-belica/sumy\n",
    "\n",
    "This program is to run LexRank's different combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# directory of data\n",
    "lexrank_extractive_dataset = \"/home/s10166858/kawaijoe/Dataset/cnn-dailymail-master/lexrank_extractive_dataset/\"\n",
    "\n",
    "# directory to store generated summaries\n",
    "system_dir = \"/home/s10166858/kawaijoe/Extractive Methods/LexRank/sumy-dev/system\"\n",
    "\n",
    "#Import library essentials\n",
    "from sumy.parsers.plaintext import PlaintextParser #Plain text parser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer #LexRank algorithm\n",
    "from sumy.utils import get_stop_words #Stopwords\n",
    "from sumy.nlp.stemmers import Stemmer #Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LexRank with No NLP (Completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in sorted(os.listdir(lexrank_extractive_dataset)):\n",
    "    final_summary = ''\n",
    "    \n",
    "    parser = PlaintextParser.from_file(lexrank_extractive_dataset + file, Tokenizer('english'))\n",
    "    summarizer = LexRankSummarizer()\n",
    "\n",
    "    #Summarize the document\n",
    "    summary = summarizer(parser.document, 4)\n",
    "    for sentence in summary:\n",
    "        final_summary = final_summary + str(sentence) + \"\\n\"\n",
    "        \n",
    "    new_filename = \"article\" + str(file[:-5]) + \"_system1.txt\"\n",
    "    new_filepath = os.path.join(system_dir, new_filename)\n",
    "\n",
    "    with open(new_filepath, \"a\") as f:\n",
    "        f.write(final_summary)\n",
    "\n",
    "print(\"Running Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LexRank with Stopwords Removal Only (Completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in sorted(os.listdir(lexrank_extractive_dataset)):\n",
    "    final_summary = ''\n",
    "    \n",
    "    parser = PlaintextParser.from_file(lexrank_extractive_dataset + file, Tokenizer('english'))\n",
    "    summarizer = LexRankSummarizer()\n",
    "    \n",
    "    summarizer.stop_words = get_stop_words('english')\n",
    "\n",
    "    #Summarize the document\n",
    "    summary = summarizer(parser.document, 4)\n",
    "    for sentence in summary:\n",
    "        final_summary = final_summary + str(sentence) + \"\\n\"\n",
    "        \n",
    "    new_filename = \"article\" + str(file[:-5]) + \"_system1.txt\"\n",
    "    new_filepath = os.path.join(system_dir, new_filename)\n",
    "\n",
    "    with open(new_filepath, \"a\") as f:\n",
    "        f.write(final_summary)\n",
    "\n",
    "print(\"Running Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LexRank with Stemming Only (Completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in sorted(os.listdir(lexrank_extractive_dataset)):\n",
    "    final_summary = ''\n",
    "    \n",
    "    parser = PlaintextParser.from_file(lexrank_extractive_dataset + file, Tokenizer('english'))\n",
    "    stemmer = Stemmer('english')\n",
    "    summarizer = LexRankSummarizer(stemmer)\n",
    "\n",
    "    #Summarize the document\n",
    "    summary = summarizer(parser.document, 4)\n",
    "    for sentence in summary:\n",
    "        final_summary = final_summary + str(sentence) + \"\\n\"\n",
    "        \n",
    "    new_filename = \"article\" + str(file[:-5]) + \"_system1.txt\"\n",
    "    new_filepath = os.path.join(system_dir, new_filename)\n",
    "    \n",
    "    \n",
    "    with open(new_filepath, \"a\") as f:\n",
    "        f.write(final_summary)\n",
    "\n",
    "print(\"Running Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LexRank with All NLP (Completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in sorted(os.listdir(lexrank_extractive_dataset)):\n",
    "    final_summary = ''\n",
    "    \n",
    "    parser = PlaintextParser.from_file(lexrank_extractive_dataset + file, Tokenizer('english'))\n",
    "    stemmer = Stemmer('english')\n",
    "    summarizer = LexRankSummarizer(stemmer)\n",
    "    summarizer.stop_words = get_stop_words('english')\n",
    "    \n",
    "    #Summarize the document\n",
    "    summary = summarizer(parser.document, 4)\n",
    "    for sentence in summary:\n",
    "        final_summary = final_summary + str(sentence) + \"\\n\"\n",
    "        \n",
    "    new_filename = \"article\" + str(file[:-5]) + \"_system1.txt\"\n",
    "    new_filepath = os.path.join(system_dir, new_filename)\n",
    "    \n",
    "    \n",
    "    with open(new_filepath, \"a\") as f:\n",
    "        f.write(final_summary)\n",
    "\n",
    "print(\"Running Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
